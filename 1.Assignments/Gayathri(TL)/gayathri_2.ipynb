{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "xl7LfISJKm8g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQIF6zT0W-Cr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for synthetic dataset\n",
        "num_classes = 2\n",
        "num_images = 100  # total images per class\n",
        "image_size = (224, 224)  # image size\n",
        "\n",
        "# Create directories\n",
        "base_dir = 'synthetic_data'\n",
        "os.makedirs(os.path.join(base_dir, 'train', 'class1'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'train', 'class2'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'val', 'class1'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'val', 'class2'), exist_ok=True)\n",
        "\n",
        "# Generate synthetic images\n",
        "for cls in range(num_classes):\n",
        "    for i in range(num_images):\n",
        "        # Create a blank image and fill it with random colors\n",
        "        image = np.random.randint(255, size=(image_size[0], image_size[1], 3), dtype=np.uint8)\n",
        "        # Save the image\n",
        "        cv2.imwrite(os.path.join(base_dir, 'train', f'class{cls + 1}', f'image_{i}.jpg'), image)\n",
        "        # For validation, save a subset of images\n",
        "        if i < 10:  # Change this number for more validation images\n",
        "            cv2.imwrite(os.path.join(base_dir, 'val', f'class{cls + 1}', f'image_{i}.jpg'), image)\n",
        "\n",
        "print(\"Synthetic dataset created.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A1oftYWXMOz",
        "outputId": "a8f4ddaa-0fd7-43a8-e871-3075d38e1595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Create ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2, shear_range=0.2,\n",
        "                                    zoom_range=0.2, horizontal_flip=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab0KmqZeXS5x",
        "outputId": "8152bbbc-5e8b-47a2-aad8-cb71bfd1483a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_model(model_name='ResNet50', input_shape=(224, 224, 3), num_classes=2):\n",
        "    if model_name == 'ResNet50':\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'VGG16':\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    else:\n",
        "        raise ValueError(\"Only ResNet50 and VGG16 are supported.\")\n",
        "\n",
        "    # Freeze all layers in the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom dense layers\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create the new model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "EYPm3juLXXWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For CIFAR-10\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "# For synthetic dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory('synthetic_data/train/', target_size=(224, 224),\n",
        "                                                    batch_size=32, class_mode='categorical')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory('synthetic_data/val/', target_size=(224, 224),\n",
        "                                                batch_size=32, class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRZnf0geXY2w",
        "outputId": "a252dc78-5b2c-4ad1-d939-99ad483c6817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model (ResNet50 or VGG16)\n",
        "model = load_pretrained_model(model_name='ResNet50', input_shape=(224, 224, 3), num_classes=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P1AiV95Xkj_",
        "outputId": "aa6fe0df-98e9-4c9b-eb01-5e33c2673511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 9s/step - accuracy: 0.4325 - loss: 1.1450 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6s/step - accuracy: 0.4421 - loss: 0.9473 - val_accuracy: 0.5000 - val_loss: 0.8605\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.5082 - loss: 0.9631 - val_accuracy: 0.5000 - val_loss: 0.7856\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.4697 - loss: 0.8451 - val_accuracy: 0.5000 - val_loss: 0.7620\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6s/step - accuracy: 0.4562 - loss: 0.8495 - val_accuracy: 0.5000 - val_loss: 0.6952\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6s/step - accuracy: 0.5316 - loss: 0.7769 - val_accuracy: 0.5000 - val_loss: 0.7492\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7s/step - accuracy: 0.5461 - loss: 0.7347 - val_accuracy: 0.5000 - val_loss: 0.7603\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7s/step - accuracy: 0.4947 - loss: 0.8346 - val_accuracy: 0.5000 - val_loss: 0.7474\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7s/step - accuracy: 0.5777 - loss: 0.7008 - val_accuracy: 0.5000 - val_loss: 0.7222\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.4981 - loss: 0.7356 - val_accuracy: 0.4500 - val_loss: 0.6935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Evaluting the model"
      ],
      "metadata": {
        "id": "3H0dFmJXK2o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test data\n",
        "test_loss, test_accuracy = model.evaluate(val_generator)  # Use validation data for evaluation\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Predictions for precision, recall, and classification report\n",
        "y_pred = model.predict(val_generator)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = val_generator.classes\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes, target_names=val_generator.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZzOcAKAXoHW",
        "outputId": "a0b25bf4-e17e-4344-c1d1-883d80f95380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.4500 - loss: 0.6935\n",
            "Test Accuracy: 0.4500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.40      0.20      0.27        10\n",
            "      class2       0.47      0.70      0.56        10\n",
            "\n",
            "    accuracy                           0.45        20\n",
            "   macro avg       0.43      0.45      0.41        20\n",
            "weighted avg       0.43      0.45      0.41        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained your model and have the validation data\n",
        "# Use val_generator to get the evaluation metrics\n",
        "\n",
        "# Evaluate on the validation data\n",
        "test_loss, test_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {test_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Predictions for precision, recall, and classification report\n",
        "y_pred = model.predict(val_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the predicted class indices\n",
        "y_true = val_generator.classes  # Get the true class indices\n",
        "\n",
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get class names\n",
        "class_names = val_generator.class_indices.keys()\n",
        "\n",
        "# Print the classification report\n",
        "report = classification_report(y_true, y_pred_classes, target_names=class_names)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvDP6mWnXq7A",
        "outputId": "68b33b68-4394-4364-ddc5-755efb2f0306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.4500 - loss: 0.6935\n",
            "Validation Loss: 0.6935\n",
            "Validation Accuracy: 0.4500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.80      0.40      0.53        10\n",
            "      class2       0.60      0.90      0.72        10\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.70      0.65      0.63        20\n",
            "weighted avg       0.70      0.65      0.63        20\n",
            "\n"
          ]
        }
      ]
    }
  ]
}